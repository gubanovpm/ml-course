{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №7\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#special for me\n",
    "#%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install cuda-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №1: \n",
    "Обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша основная задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку первого занятия.\n",
    "\n",
    "Настоятельно рекомендуем написать код \"с нуля\", лишь поглядывая на готовые примеры, а не просто \"скопировать-вставить\". Это поможет вам в дальнейшем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 3')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f'Image label: {_label}')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 92% accuracy.\n",
    "\n",
    "*Комментарий: для этого достаточно линейных слоев и функций активации.*\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model`.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StupidNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StupidNN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Creating model instance\n",
    "model = StupidNN().to(device) # your code here\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model is not None, 'Please, use `model` variable to store your model'\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].reshape(-1, 784)\n",
    "    y = random_batch[1]\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model(x)    \n",
    "except Exception as e:\n",
    "    print('Something is wrong with the model')\n",
    "    raise e\n",
    "    \n",
    "    \n",
    "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
    "\n",
    "print('Everything seems fine!')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройте параметры модели на обучающей выборке. Рекомендуем поработать с различными оптимизаторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 8\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.244125  [   32/60000]\n",
      "loss: 0.291798  [ 3232/60000]\n",
      "loss: 0.570548  [ 6432/60000]\n",
      "loss: 0.329486  [ 9632/60000]\n",
      "loss: 0.421884  [12832/60000]\n",
      "loss: 0.297929  [16032/60000]\n",
      "loss: 0.271834  [19232/60000]\n",
      "loss: 0.252993  [22432/60000]\n",
      "loss: 0.626711  [25632/60000]\n",
      "loss: 0.150087  [28832/60000]\n",
      "loss: 0.146505  [32032/60000]\n",
      "loss: 0.231789  [35232/60000]\n",
      "loss: 0.561992  [38432/60000]\n",
      "loss: 0.150210  [41632/60000]\n",
      "loss: 0.216799  [44832/60000]\n",
      "loss: 0.230149  [48032/60000]\n",
      "loss: 0.132401  [51232/60000]\n",
      "loss: 0.370968  [54432/60000]\n",
      "loss: 0.346826  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.291276 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.198115  [   32/60000]\n",
      "loss: 0.385758  [ 3232/60000]\n",
      "loss: 0.446123  [ 6432/60000]\n",
      "loss: 0.290888  [ 9632/60000]\n",
      "loss: 0.577636  [12832/60000]\n",
      "loss: 0.185085  [16032/60000]\n",
      "loss: 0.313485  [19232/60000]\n",
      "loss: 0.207374  [22432/60000]\n",
      "loss: 0.306897  [25632/60000]\n",
      "loss: 0.200881  [28832/60000]\n",
      "loss: 0.437309  [32032/60000]\n",
      "loss: 0.347933  [35232/60000]\n",
      "loss: 0.412144  [38432/60000]\n",
      "loss: 0.353854  [41632/60000]\n",
      "loss: 0.521064  [44832/60000]\n",
      "loss: 0.486510  [48032/60000]\n",
      "loss: 0.108516  [51232/60000]\n",
      "loss: 0.155069  [54432/60000]\n",
      "loss: 0.485894  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.285894 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.280143  [   32/60000]\n",
      "loss: 0.337576  [ 3232/60000]\n",
      "loss: 0.463184  [ 6432/60000]\n",
      "loss: 0.168443  [ 9632/60000]\n",
      "loss: 0.322971  [12832/60000]\n",
      "loss: 0.207726  [16032/60000]\n",
      "loss: 0.154207  [19232/60000]\n",
      "loss: 0.275278  [22432/60000]\n",
      "loss: 0.247266  [25632/60000]\n",
      "loss: 0.214621  [28832/60000]\n",
      "loss: 0.275545  [32032/60000]\n",
      "loss: 0.537039  [35232/60000]\n",
      "loss: 0.643730  [38432/60000]\n",
      "loss: 0.303077  [41632/60000]\n",
      "loss: 0.285529  [44832/60000]\n",
      "loss: 0.226253  [48032/60000]\n",
      "loss: 0.078897  [51232/60000]\n",
      "loss: 0.497339  [54432/60000]\n",
      "loss: 0.408641  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.280984 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.246102  [   32/60000]\n",
      "loss: 0.705612  [ 3232/60000]\n",
      "loss: 0.180179  [ 6432/60000]\n",
      "loss: 0.259360  [ 9632/60000]\n",
      "loss: 0.297959  [12832/60000]\n",
      "loss: 0.327915  [16032/60000]\n",
      "loss: 0.339561  [19232/60000]\n",
      "loss: 0.454526  [22432/60000]\n",
      "loss: 0.552678  [25632/60000]\n",
      "loss: 0.336843  [28832/60000]\n",
      "loss: 0.298793  [32032/60000]\n",
      "loss: 0.505595  [35232/60000]\n",
      "loss: 0.351098  [38432/60000]\n",
      "loss: 0.323526  [41632/60000]\n",
      "loss: 0.288867  [44832/60000]\n",
      "loss: 0.231784  [48032/60000]\n",
      "loss: 0.316919  [51232/60000]\n",
      "loss: 0.242840  [54432/60000]\n",
      "loss: 0.401088  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.276329 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.132085  [   32/60000]\n",
      "loss: 0.171630  [ 3232/60000]\n",
      "loss: 0.174701  [ 6432/60000]\n",
      "loss: 0.093078  [ 9632/60000]\n",
      "loss: 0.233197  [12832/60000]\n",
      "loss: 0.252689  [16032/60000]\n",
      "loss: 0.281239  [19232/60000]\n",
      "loss: 0.467198  [22432/60000]\n",
      "loss: 0.256682  [25632/60000]\n",
      "loss: 0.051456  [28832/60000]\n",
      "loss: 0.365706  [32032/60000]\n",
      "loss: 0.160588  [35232/60000]\n",
      "loss: 0.312513  [38432/60000]\n",
      "loss: 0.456593  [41632/60000]\n",
      "loss: 0.229394  [44832/60000]\n",
      "loss: 0.209712  [48032/60000]\n",
      "loss: 0.157302  [51232/60000]\n",
      "loss: 0.270097  [54432/60000]\n",
      "loss: 0.268801  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.273195 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.214637  [   32/60000]\n",
      "loss: 0.334567  [ 3232/60000]\n",
      "loss: 0.293344  [ 6432/60000]\n",
      "loss: 0.255560  [ 9632/60000]\n",
      "loss: 0.289181  [12832/60000]\n",
      "loss: 0.284958  [16032/60000]\n",
      "loss: 0.260683  [19232/60000]\n",
      "loss: 0.448349  [22432/60000]\n",
      "loss: 0.273996  [25632/60000]\n",
      "loss: 0.384524  [28832/60000]\n",
      "loss: 0.369203  [32032/60000]\n",
      "loss: 0.252787  [35232/60000]\n",
      "loss: 0.433087  [38432/60000]\n",
      "loss: 0.469930  [41632/60000]\n",
      "loss: 0.100015  [44832/60000]\n",
      "loss: 0.200148  [48032/60000]\n",
      "loss: 0.560468  [51232/60000]\n",
      "loss: 0.497286  [54432/60000]\n",
      "loss: 0.418245  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.268724 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.315808  [   32/60000]\n",
      "loss: 0.120697  [ 3232/60000]\n",
      "loss: 0.352430  [ 6432/60000]\n",
      "loss: 0.269545  [ 9632/60000]\n",
      "loss: 0.113432  [12832/60000]\n",
      "loss: 0.303711  [16032/60000]\n",
      "loss: 0.213279  [19232/60000]\n",
      "loss: 0.471535  [22432/60000]\n",
      "loss: 0.275681  [25632/60000]\n",
      "loss: 0.446357  [28832/60000]\n",
      "loss: 0.436024  [32032/60000]\n",
      "loss: 0.097708  [35232/60000]\n",
      "loss: 0.261435  [38432/60000]\n",
      "loss: 0.152302  [41632/60000]\n",
      "loss: 0.363801  [44832/60000]\n",
      "loss: 0.159559  [48032/60000]\n",
      "loss: 0.360629  [51232/60000]\n",
      "loss: 0.608070  [54432/60000]\n",
      "loss: 0.130981  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.265235 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.092629  [   32/60000]\n",
      "loss: 0.358828  [ 3232/60000]\n",
      "loss: 0.565838  [ 6432/60000]\n",
      "loss: 0.336488  [ 9632/60000]\n",
      "loss: 0.222623  [12832/60000]\n",
      "loss: 0.147676  [16032/60000]\n",
      "loss: 0.171985  [19232/60000]\n",
      "loss: 0.255670  [22432/60000]\n",
      "loss: 0.110015  [25632/60000]\n",
      "loss: 0.145556  [28832/60000]\n",
      "loss: 0.551497  [32032/60000]\n",
      "loss: 0.551995  [35232/60000]\n",
      "loss: 0.378973  [38432/60000]\n",
      "loss: 0.233646  [41632/60000]\n",
      "loss: 0.097544  [44832/60000]\n",
      "loss: 0.118881  [48032/60000]\n",
      "loss: 0.162144  [51232/60000]\n",
      "loss: 0.148775  [54432/60000]\n",
      "loss: 0.267941  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.261462 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.315131  [   32/60000]\n",
      "loss: 0.228917  [ 3232/60000]\n",
      "loss: 0.139333  [ 6432/60000]\n",
      "loss: 0.217618  [ 9632/60000]\n",
      "loss: 0.104191  [12832/60000]\n",
      "loss: 0.147189  [16032/60000]\n",
      "loss: 0.586809  [19232/60000]\n",
      "loss: 0.233451  [22432/60000]\n",
      "loss: 0.347616  [25632/60000]\n",
      "loss: 0.226774  [28832/60000]\n",
      "loss: 0.333959  [32032/60000]\n",
      "loss: 0.079054  [35232/60000]\n",
      "loss: 0.610616  [38432/60000]\n",
      "loss: 0.286681  [41632/60000]\n",
      "loss: 0.323291  [44832/60000]\n",
      "loss: 0.198319  [48032/60000]\n",
      "loss: 0.253572  [51232/60000]\n",
      "loss: 0.116808  [54432/60000]\n",
      "loss: 0.337613  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.258641 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.477930  [   32/60000]\n",
      "loss: 0.180854  [ 3232/60000]\n",
      "loss: 0.177349  [ 6432/60000]\n",
      "loss: 0.277860  [ 9632/60000]\n",
      "loss: 0.198372  [12832/60000]\n",
      "loss: 0.428555  [16032/60000]\n",
      "loss: 0.467500  [19232/60000]\n",
      "loss: 0.169162  [22432/60000]\n",
      "loss: 0.140916  [25632/60000]\n",
      "loss: 0.214978  [28832/60000]\n",
      "loss: 0.367105  [32032/60000]\n",
      "loss: 0.308309  [35232/60000]\n",
      "loss: 0.300433  [38432/60000]\n",
      "loss: 0.351698  [41632/60000]\n",
      "loss: 0.158219  [44832/60000]\n",
      "loss: 0.317599  [48032/60000]\n",
      "loss: 0.155681  [51232/60000]\n",
      "loss: 0.195835  [54432/60000]\n",
      "loss: 0.161398  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.255895 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_data_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_data_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.92515\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9275\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
    "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Загрузите файл `hw07_data_dict.npy` (ссылка есть на странице с заданием) и запустите код ниже для генерации посылки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_hw07.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import os\n",
    "import json\n",
    "assert os.path.exists('hw07_data_dict.npy'), 'Please, download `hw07_data_dict.npy` and place it in the working directory'\n",
    "\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "    \n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "    \n",
    "    predicted_labels = torch.cat(predicted_labels).numpy()\n",
    "    predicted_labels = ','.join([str(x) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "loaded_data_dict = np.load('hw07_data_dict.npy', allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])),\n",
    "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test']))\n",
    "}\n",
    "\n",
    "with open('submission_dict_hw07.json', 'w') as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print('File saved to `submission_dict_hw07.json`')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
